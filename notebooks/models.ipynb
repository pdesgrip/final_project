{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc526a-4c0e-4dcf-b083-d586d2a7eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Actual vs. Predicted Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Identity line\n",
    "plt.title('Actual vs. Predicted Counts')\n",
    "plt.xlabel('Actual Counts')\n",
    "plt.ylabel('Predicted Counts')\n",
    "plt.show()\n",
    "\n",
    "# 2. Residuals Plot\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.title('Residuals vs. Predicted Counts')\n",
    "plt.xlabel('Predicted Counts')\n",
    "plt.ylabel('Residuals')\n",
    "plt.hlines(0, min(y_pred), max(y_pred), colors='red')\n",
    "plt.show()\n",
    "\n",
    "# If using a Random Forest model, the third visualization would be:\n",
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = feature_importance.argsort()\n",
    "plt.barh(encoded_df.columns[sorted_idx], feature_importance[sorted_idx])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Filter to only include sightings of top N birds\n",
    "top_birds = data['COMMON NAME'].value_counts().nlargest(10).index\n",
    "filtered_data = data[data['COMMON NAME'].isin(top_birds)]\n",
    "\n",
    "# Group by STATE and COMMON NAME, get count\n",
    "grouped_data = filtered_data.groupby(['STATE', 'COMMON NAME']).size().reset_index(name='COUNT')\n",
    "\n",
    "# One-hot encode the 'STATE' and 'COMMON NAME' columns\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(grouped_data[['STATE', 'COMMON NAME']])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['STATE', 'COMMON NAME']))\n",
    "\n",
    "# Split data into training and test sets\n",
    "X = encoded_df\n",
    "y = grouped_data['COUNT']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a regression model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
