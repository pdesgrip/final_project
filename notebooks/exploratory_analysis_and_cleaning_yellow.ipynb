{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a702e0-b37a-4143-ac46-0e1da2829de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "from scipy.stats import skew, zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sys.path.append('../')\n",
    "from cleaners.cleaners import clean_dataframe, clean_dataframe_columns, unique_values_count, n_counts_and_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bc115-6a36-45af-bf0d-f9206287e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "\n",
    "path = '../data/yellow'\n",
    "all_files = glob.glob(path + \"/*.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d721a-991b-4da6-92ff-8d6812bc30e2",
   "metadata": {},
   "source": [
    "There are over 400M rows on the raw concatenated DF - I think this may be too taxing for models and a drag to import - reduced to 40K random sample to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20815bf4-db2f-4e82-a92a-5e8232d418c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses function to load, clean column names, and sample each file\n",
    "\n",
    "fraction = 0.0001  # sample fraction of rows\n",
    "seed = 33 # use seed for consistency\n",
    "\n",
    "# uses function to clean df columns\n",
    "sampled_dfs = [clean_dataframe_columns(pd.read_parquet(file).sample(frac=fraction)) for file in all_files]\n",
    "\n",
    "# concat all sampled names\n",
    "final_df = pd.concat(sampled_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24838d52-4be2-4401-99f2-9eebc887a863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine frame/columns\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec08e4-d8d4-45f8-9212-ff0deef22116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at payment types as there are some differences from the reference materials\n",
    "\n",
    "result = unique_values_count(final_df, 'payment_type')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a4adb-7328-4021-96d9-46467233408c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac37eb-2319-4b1e-be93-1a02bc4e9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vendor ID counts should only be 1 or 2 - dropping this column in any case\n",
    "\n",
    "vendorid_counts = final_df['vendorid'].value_counts()\n",
    "\n",
    "print(vendorid_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12105f-c34c-4b2a-b1ac-0440af9bae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten syntax\n",
    "df=final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98540cb4-3b6e-4fd3-899c-1f8d40a2b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view 100 random sampled rows\n",
    "\n",
    "sampled_df = df.sample(n=100)\n",
    "display(sampled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b32e94-11f2-4287-949e-aafe646f3435",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b33b72-462a-4ef7-a140-c3e10ee1b6de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sampled_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec418a69-bb95-49cc-9b28-e0940d5c7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there were 2 airport fee columns, we need to stardardize before the concat - done at import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f965a4e-6e58-4815-864a-00a93a728f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are only 2 (the other instances appear to be typos) so this column can be dropped since such general info is not of use to us\n",
    "# the improvement_surcharge is a standard add-on fall all fares so we can drop this too\n",
    "# the airport fee is redundant since the ratecode includes the airport info - drop\n",
    "# congestion surcharge is also not of use for us as well as store/fwrd flag, mta tax and extra (incorporated already in fare info) - drop.\n",
    "\n",
    "\n",
    "final_df.drop(columns=['vendorid', 'improvement_surcharge', 'store_and_fwd_flag', 'mta_tax', 'extra', 'airport_fee', 'congestion_surcharge'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd920000-b167-4d06-8851-556f7c345391",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362ad72-337c-4b90-985d-0bfdd118bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c013d02-a9f8-4c61-97e8-dd19000a845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at unique values for payment types using my function\n",
    "\n",
    "result = unique_values_count(final_df, 'payment_type')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd4bc9-86bd-4b9f-b017-cc06fd49a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses my function to list values for each column (the user can speicfy how many columns) and the number of instances of each value\n",
    "display(n_counts_and_values(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12db14-f0d5-47c5-863f-f6f29501508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining the rows with NaNs\n",
    "\n",
    "pd.set_option('display.max_rows', 500)  # Set the maximum display rows to 500\n",
    "nan_rows = final_df[final_df['passenger_count'].isna()]\n",
    "\n",
    "nan_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f11729-aea7-4663-974c-e6930b389118",
   "metadata": {},
   "source": [
    "The NaNs and 0s for passenger_count and the other 2 columns make up ~ 1.2% of the data and are randomly distributed so it is safe to drop these rows.\n",
    "They could theoretically be fares without passengers but there is no info in the documentation about so I prefer not to guess in this instance without significant domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b413e4-7162-4a75-a0ea-16f94ec20f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the rows with NaNs\n",
    "final_df.dropna(subset=['passenger_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc863e55-b811-446e-b88c-6987c8d4cc90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922020f4-8982-4188-8789-0bbcb37717fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would like to add a new column to define a trip duration using the pickup/drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b9c3e-2daa-4818-a29e-9cb3f1503ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f230940e-894b-402f-ab02-f4648a87da36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creates new col -- trip_duration\n",
    "final_df['trip_duration'] = (final_df['tpep_dropoff_datetime'] - final_df['tpep_pickup_datetime']).astype('timedelta64[us]')  \n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c4c4d-8b14-4a26-81fe-0da3be020df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the timedelta format to seconds (float)\n",
    "final_df['trip_duration_seconds'] = final_df['trip_duration'].dt.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73543c6-9f17-43d0-9872-57c58a120dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836a378-75b5-4ace-a45d-5d577ecb0b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df['trip_duration_seconds'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0607fd-27a4-4b58-bc02-f072d86ad71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop previous column as it is now in secoonds\n",
    "df.drop('trip_duration', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c25cae-4184-48c7-8bc9-52744c7751b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check this col for NaNs or non-positive values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3e6b4-766e-4558-a1fa-8e1930abc6d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4670255-db09-4df6-b6c1-d9f3dc1d92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last check for NaNs\n",
    "num_rows_with_nan = final_df.isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with NaN values: {num_rows_with_nan}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad726d-d27d-4d6d-9bc5-7536ddbf57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d63cfb-a80a-4544-a0e6-c88dd0166f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7adc85d-a048-430f-a768-1802cf5c9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned and updated DataFrame as a CSV file (for tableau use) and a parquet file (retains datetime if opened again)\n",
    "final_df.to_csv('../data/yellow/taxi_y_cleaned.csv', index=False)\n",
    "final_df.to_parquet('../data/yellow/taxi_y_cleaned.parquet', index=False, engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55fcb8-5631-4ebc-ae6b-789f6c14a02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
