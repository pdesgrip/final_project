{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc526a-4c0e-4dcf-b083-d586d2a7eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0217aec-86f1-4083-be94-25e54360c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the cleaned CSV\n",
    "data_csv = pd.read_csv('../data/yellow/taxi_y_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5c318-6ade-4672-848c-3473a84c39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8552f01-8dde-422c-b248-0aa69da69324",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_csv.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb9bf9-1c6a-4882-8412-74552cd0cd79",
   "metadata": {},
   "source": [
    "Since pickup, dropoff are datetime and we have duration let's drop them.\n",
    "rate_code, pu_location, do_location and payment_type are all categorial so will need encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e631d0-c665-4bb9-a96b-0f6d52148d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop datetime columns\n",
    "data_csv = data_csv.drop(columns=['tpep_pickup_datetime', 'tpep_dropoff_datetime'])\n",
    "\n",
    "# one hot encode for the categorical variables\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_features = encoder.fit_transform(data_csv[['ratecodeid', 'pulocationid', 'dolocationid', 'payment_type']])\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['ratecodeid', 'pulocationid', 'dolocationid', 'payment_type']))\n",
    "\n",
    "# combine the original dataframe with the encoded dataframe\n",
    "data_encoded = pd.concat([data_csv.drop(columns=['ratecodeid', 'pulocationid', 'dolocationid', 'payment_type']), encoded_df], axis=1)\n",
    "\n",
    "# check the first few rows of the encoded data\n",
    "data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42804d8-2f32-499e-85fc-f3ad38a8fce4",
   "metadata": {},
   "source": [
    "we will use VIF to indentify if there is multicolinearity in the numerical columns as categorical are so numerous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f7a31-0690-4eb5-9484-473bce52a3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select numeric, add intercetp and constant\n",
    "main_numeric_cols = ['passenger_count', 'trip_distance', 'fare_amount', 'tolls_amount', 'total_amount', 'trip_duration_seconds']\n",
    "X_main_numeric = data_csv[main_numeric_cols].copy()\n",
    "X_main_numeric['intercept'] = 1\n",
    "\n",
    "# calculate VIF for numeric predictors\n",
    "vif_data_main_numeric = pd.DataFrame()\n",
    "vif_data_main_numeric[\"Variable\"] = X_main_numeric.columns\n",
    "vif_data_main_numeric[\"VIF\"] = [variance_inflation_factor(X_main_numeric.values, i) for i in range(X_main_numeric.shape[1])]\n",
    "\n",
    "# sort values\n",
    "vif_data_main_numeric_sorted = vif_data_main_numeric.sort_values(by=\"VIF\", ascending=False)\n",
    "\n",
    "vif_data_main_numeric_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb417f4b-29bc-49f8-97ac-0e4574dd206e",
   "metadata": {},
   "source": [
    "total_amount and fare_amount have high VIFs which indicate multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6407e-67b0-42c0-94dc-0d8629a581f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop 'total_amount' from the predictor\n",
    "X_final = data_encoded.drop(columns=['tip_amount', 'total_amount'])\n",
    "y_final = data_encoded['tip_amount']\n",
    "\n",
    "# splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.25, random_state=33)\n",
    "\n",
    "# run the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluation\n",
    "rmse = round(np.sqrt(mean_squared_error(y_test, y_pred)), 2)\n",
    "r2 = round(r2_score(y_test, y_pred), 2)\n",
    "\n",
    "\n",
    "rmse, r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa60435b-ccfa-4188-a6c4-6d77b0eb412a",
   "metadata": {},
   "source": [
    "RMSE of 1.91 is 'fair' in the context of tips here. 0.53 r2 seems middling showing the the model accounts for 53% of the variance in the tip amount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4e363-2d0a-4675-9b0c-3eb7c11e3983",
   "metadata": {},
   "source": [
    "As we might expect there is high colinearity between fare_amount, tolls amount, and total_amount. We will drop total_amount since it is a derivation of these other columns in this case for the LR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1725f-35e5-4162-a05c-cab1a79b9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# make plots\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "# actual v predicted\n",
    "sns.scatterplot(x=y_test, y=y_pred, ax=ax[0], alpha=0.5)\n",
    "ax[0].set_title('Actual vs. Predicted')\n",
    "ax[0].set_xlabel('Actual Values')\n",
    "ax[0].set_ylabel('Predicted Values')\n",
    "ax[0].plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2)  # 45-degree line\n",
    "ax[0].legend(['Identity Line', 'Predictions'])\n",
    "\n",
    "# residuals v predicted\n",
    "sns.scatterplot(x=y_pred, y=residuals, ax=ax[1], alpha=0.5)\n",
    "ax[1].set_title('Residuals vs. Predicted')\n",
    "ax[1].set_xlabel('Predicted Values')\n",
    "ax[1].set_ylabel('Residuals')\n",
    "ax[1].axhline(y=0, color='red', lw=2)\n",
    "\n",
    "# histogram of Residuals\n",
    "sns.histplot(residuals, ax=ax[2], bins=50, kde=True)\n",
    "ax[2].set_title('Histogram of Residuals')\n",
    "ax[2].set_xlabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e82ca-07b5-47a0-b403-9fcfbd67b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pickle to save model\n",
    "\n",
    "with open('../models/linear_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77274c-8603-4c18-9fb1-9f4ed2d2067f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_encoded.to_csv('../data/yellow/taxi_y_1HE.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789289b7-d94f-4b0f-bad1-c2ac130eb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement below based on time constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4696c1f-a770-4526-b2d9-6802e2136e1f",
   "metadata": {},
   "source": [
    "# ask user for input\n",
    "input_data = {}\n",
    "print(\"Please enter the following details to predict the tip amount:\")\n",
    "input_data['passenger_count'] = int(input(\"Passenger count: \"))\n",
    "input_data['trip_distance'] = float(input(\"Trip distance (in miles): \"))\n",
    "\n",
    "\n",
    "# Convert user input to DataFrame\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "\n",
    "# predicting with model\n",
    "predicted_tip = model.predict(processed_input_df)\n",
    "\n",
    "# output\n",
    "print(f\"Predicted tip amount: ${predicted_tip[0]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
